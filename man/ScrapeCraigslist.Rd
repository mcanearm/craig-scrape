% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/ScrapeCraigslist.R
\name{ScrapeCraigslist}
\alias{ScrapeCraigslist}
\title{Craigslist Scraper}
\usage{
ScrapeCraigslist(url, row.selector, fields)
}
\arguments{
\item{url}{A text string of the link to crawl}

\item{row.selector}{The CSS element of rows}

\item{fields}{A text vector of the CSS fields used to identify wanted information within
the rows.}
}
\value{
A single data frame containing all the elements scraped, with the CSS selector
listed as the name of each column.
}
\description{
From a general list style page, scrape the first page with desired data using
css selectors.
}
\details{
For Craigslist pages, this function finds the row on a page,
and using CSS selector that you specify, scrapes data from each row into a nice data frame
for research and munging purposes. This package extensively uses \code{rvest} functions.
}
\examples{
url <- 'http://philadelphia.craigslist.org/search/apa'
fields <- c('time', '.hdrlnk', '.housing', 'small', '.price')
philly.apts <- ScrapeCraigslist(url, '.row', fields)

# Clean up the price data
philly.apts[, 5] <- as.integer(gsub('\\\\$', '', philly.apts[, 5]))
}

