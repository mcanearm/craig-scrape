% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/ScrapeList.R
\name{ScrapeList}
\alias{ScrapeList}
\title{General List scraper}
\usage{
ScrapeList(url, row.selector, fields)
}
\arguments{
\item{url}{The link to crawl}

\item{row.selector}{The CSS element of rows}

\item{fields}{A text vector of the CSS fields used to identify wanted information within
the rows.}
}
\value{
A single data frame containing all the elements scraped, with the CSS selector
listed as the name of each column.
}
\description{
From a general list style page, scrape the first page with desired data using
css selectors.
}
\details{
For websites that come in a 'list' or 'feed' format, this function finds the row on a page,
and using CSS selector that you specify, scrapes data from each row into a nice data frame
for research and munging purposes. This package extensively uses \code{rvest} functions.
}
\examples{
url <- 'http://philadelphia.craigslist.org/search/apa'
fields <- c('time', '.hdrlnk', '.housing', 'small', '.price')
philly.apts <- ScrapeList(url, '.row', fields)
}

